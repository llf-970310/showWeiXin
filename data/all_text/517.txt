新闻快播
――――――――――――――――――――――
AlphaGo 3:0提前锁定胜局
――――――――――――――――――――――
3月12日，人机大战第三场已经结束，世界围棋冠军李世石遭遇三连败，五番棋比赛中谷歌AlphaGo已赢得胜利




标签

AlphaGo

阿尔法围棋(AlphaGo)是一款围棋人工智能程序，由位于英国伦敦的谷歌(Google)旗下DeepMind公司的戴维・西尔弗、艾佳・黄和戴密斯・哈萨比斯与他们的团队开发，这个程序利用“价值网络”去计算局面，用“策略网络”去选择下子。


起初，围棋人工智能长期以来举步维艰，顶级人工智能甚至不能打败稍强的业余选手。这似乎也合情合理：国际象棋中，平均每回合有35种可能，一盘棋可以有80回合；相比之下，围棋每回合有250种可能，一盘棋可以长达150回合。所以粗略来说，要是人工智能用暴力列举所有情况的方式，围棋需要计算250150种情况，大致是10360。而已经观测到的宇宙中，原子的数量才1080。

然而，AlphaGo做到了！


深度学习






阿尔法围棋(AlphaGo)的主要工作原理是“深度学习”。“深度学习”是指多层的人工神经网络和训练它的方法。一层神经网络会把大量矩阵数字作为输入，通过非线性激活方法取权重，再产生另一个数据集合作为输出。这就像生物神经大脑的工作机理一样，通过合适的矩阵数量，多层组织链接一起，形成神经网络“大脑”进行精准复杂的处理，就像人们识别物体标注图片一样。

计算机眼中的围棋落子思路

两个大脑
　　阿尔法围棋(AlphaGo)是通过两个不同神经网络“大脑”合作来改进下棋。这些大脑是多层神经网络跟那些Google图片搜索引擎识别图片在结构上是相似的。它们从多层启发式二维过滤器开始，去处理围棋棋盘的定位，就像图片分类器网络处理图片一样。经过过滤，13 个完全连接的神经网络层产生对它们看到的局面判断。这些层能够做分类和逻辑推理。
　　这些网络通过反复训练来检查结果，再去校对调整参数，去让下次执行更好。这个处理器有大量的随机性元素，所以人们是不可能精确知道网络是如何“思考”的，但更多的训练后能让它进化到更好。



第一大脑：落子选择器 (Move Picker)
阿尔法围棋(AlphaGo)的第一个神经网络大脑是“监督学习的策略网络(Policy Network)” ，观察棋盘布局企图找到最佳的下一步。事实上，它预测每一个合法下一步的最佳概率，那么最前面猜测的就是那个概率最高的。这可以理解成“落子选择器”。

第二大脑：棋局评估器 (Position Evaluator)
阿尔法围棋(AlphaGo)的第二个大脑相对于落子选择器是回答另一个问题。不是去猜测具体下一步，它预测每一个棋手赢棋的可能，在给定棋子位置情况下。这“局面评估器”就是“价值网络(Value Network)”，通过整体局面判断来辅助落子选择器。这个判断仅仅是大概的，但对于阅读速度提高很有帮助。通过分类潜在的未来局面的“好”与“坏”，AlphaGo能够决定是否通过特殊变种去深入阅读。如果局面评估器说这个特殊变种不行，那么AI就跳过阅读在这一条线上的任何更多落子。
更重要的是，人会因为情感的变化而影响自己的判断，尤其是进入到读秒的阶段时更容易产生失误，而AlphaGo不会！


Ps：AlphaGo已经取得了比赛的胜利可以拿走100万美元奖金，谷歌表示会将所得奖金全部捐赠给联合国儿童基金会、STEM(科学、技术、工程、数学)教育及围棋等相关慈善团体。




参考资料：科普中国、红网、奥创智能网、腾讯新闻


责任编辑：姜清源
